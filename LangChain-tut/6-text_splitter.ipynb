{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8228f4-21e5-4a4c-a59a-95939a1a16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apirl 2025\n",
    "# text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb060f70-2b91-4323-86fc-d0a7e8c829d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a595a003-6654-4a41-9e41-b58cea7fdac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size =10\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d24efa-217a-4b01-b4df-235854218d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a2be7f-cf33-4c5e-9d36-7e5d3951f82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghij', 'ghijklmnop', 'mnopqrstuv', 'stuvwxyz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1313ed0f-fbe5-4f22-bd91-6b8514b270de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22b2b0e-1afe-4bfd-bb8f-6d32d602e53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghij', 'ghijklmnop', 'mnopqrstuv', 'stuvwxyz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ''\n",
    ")\n",
    "c_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984750d-a56c-41d8-a57b-e1f70aad3a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87dd55-9174-4946-a126-d0547e43654e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d31661-78b6-470b-b697-02b9c9ad68f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4287180-0e32-4243-b7d8-c9fe30da2912",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " ',',\n",
       " ' the',\n",
       " ' first',\n",
       " ' one',\n",
       " ' is',\n",
       " ' just',\n",
       " ' foo',\n",
       " ' then',\n",
       " ' you',\n",
       " '�',\n",
       " '�',\n",
       " 've',\n",
       " ' got',\n",
       " ' a',\n",
       " ' space',\n",
       " ',',\n",
       " ' and',\n",
       " ' then',\n",
       " ' bar',\n",
       " ',',\n",
       " ' and',\n",
       " ' then',\n",
       " ' you',\n",
       " '�',\n",
       " '�',\n",
       " 've',\n",
       " ' got',\n",
       " ' a',\n",
       " ' space',\n",
       " ',',\n",
       " ' and',\n",
       " ' just',\n",
       " ' the',\n",
       " ' B',\n",
       " ' then',\n",
       " ' AZ',\n",
       " ' then',\n",
       " ' Z',\n",
       " 'Y',\n",
       " ',',\n",
       " ' and',\n",
       " ' then',\n",
       " ' foo',\n",
       " ' again',\n",
       " '.',\n",
       " ' And',\n",
       " ' this',\n",
       " ' shows',\n",
       " ' a',\n",
       " ' little',\n",
       " ' bit',\n",
       " ' of',\n",
       " ' the',\n",
       " ' difference',\n",
       " ' between',\n",
       " ' splitting',\n",
       " ' on',\n",
       " ' characters',\n",
       " ' versus',\n",
       " ' splitting',\n",
       " ' on',\n",
       " ' tokens',\n",
       " '.',\n",
       " ' Let',\n",
       " '�',\n",
       " '�',\n",
       " 's',\n",
       " ' apply',\n",
       " ' this',\n",
       " ' to',\n",
       " ' the',\n",
       " ' PDF',\n",
       " ' that',\n",
       " ' we',\n",
       " ' loaded',\n",
       " ' above',\n",
       " ',',\n",
       " ' and',\n",
       " ' in',\n",
       " ' a',\n",
       " ' similar',\n",
       " ' way',\n",
       " ',',\n",
       " ' we',\n",
       " ' can',\n",
       " ' call',\n",
       " ' the',\n",
       " ' split',\n",
       " ' documents',\n",
       " ' on',\n",
       " ' the',\n",
       " ' pages',\n",
       " ',',\n",
       " ' and',\n",
       " ' if',\n",
       " ' we',\n",
       " ' take',\n",
       " ' a',\n",
       " ' look',\n",
       " ' at',\n",
       " ' the',\n",
       " ' first',\n",
       " ' document',\n",
       " ',',\n",
       " ' we',\n",
       " ' have',\n",
       " ' our',\n",
       " ' new',\n",
       " ' split',\n",
       " ' document',\n",
       " ' with',\n",
       " ' the',\n",
       " ' page',\n",
       " ' content',\n",
       " ' being',\n",
       " ' roughly',\n",
       " ' the',\n",
       " ' title',\n",
       " ',',\n",
       " ' and',\n",
       " ' then',\n",
       " ' we',\n",
       " '�',\n",
       " '�',\n",
       " 've',\n",
       " ' got',\n",
       " ' the',\n",
       " ' metadata',\n",
       " ' of',\n",
       " ' the',\n",
       " ' source',\n",
       " ' and',\n",
       " ' the',\n",
       " ' page',\n",
       " ' where',\n",
       " ' it',\n",
       " ' came',\n",
       " ' from',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'So, the first one is just foo then you’ve got a space, and then bar, and then you’ve got a space, and just the B then AZ then ZY, and then foo again. And this shows a little bit of the difference between splitting on characters versus splitting on tokens. Let’s apply this to the PDF that we loaded above, and in a similar way, we can call the split documents on the pages, and if we take a look at the first document, we have our new split document with the page content being roughly the title, and then we’ve got the metadata of the source and the page where it came from.'\n",
    "\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90fa4b-1253-4133-be24-2a1e7ddf84d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
