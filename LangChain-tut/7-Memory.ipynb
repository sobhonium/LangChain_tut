{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a143b3-f293-4d47-85b7-2e15a22803a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# April 2025\n",
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006a48b-1dd5-4968-899b-08a17a84927d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e612a77-c7a0-4c96-a6c0-8cf57bb622b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc91fa-2aea-4ebb-9c4f-8233a801bfdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308a1d4-eb5a-457b-b407-f5a122488ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9ac7f-1930-4d87-b34c-995b09384c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c717b-cf5c-4dcb-b728-d6f8d373f5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11674d5e-8881-4b13-a6b4-6fd6f8ba765e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Define prompts\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate a factual question about {topic}.\",\n",
    ")\n",
    "\n",
    "# answer_prompt = PromptTemplate(\n",
    "#     input_variables=[\"question\"],\n",
    "#     template=\"Answer the question: {question}\",\n",
    "# )\n",
    "\n",
    "# # Step 3: Define LLM chains\n",
    "question_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"question\")\n",
    "# answer_chain = LLMChain(llm=llm, prompt=answer_prompt, output_key=\"answer\")\n",
    "\n",
    "# # Step 4: Create SequentialChain\n",
    "# chain = SequentialChain(\n",
    "#     # chains=[question_chain, answer_chain],\n",
    "#     chains=[question_chain],\n",
    "#     input_variables=[\"topic\"],\n",
    "#     output_variables=[\"question\", \"answer\"],\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2a30b-6b6d-4b16-9f65-c2cb6d0614f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3357a3-51cf-4be4-979b-586e5c7a94fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = question_chain.invoke({\"topic\": \"supercomputers\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e80a4-f3cf-488c-ae40-10f7db94b445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29227fae-5c63-4219-95df-14d5ac442c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By defaults, there is no memory defined for the chain\n",
    "type(question_chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c56c7-5149-4e00-aeb9-38dbca85b39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ca686-7e8b-4f88-9575-8dd8a42a7ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16815ab-c886-420c-bd2f-a4fd9a49608a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf3e32-4606-42a8-8fa1-511a4dede166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "question_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"question\", memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa17c5-1ad1-45e6-bc72-7cce78542c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = question_chain.invoke({\"topic\": \"supercomputers\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07785c-9ded-4395-ad17-d64ecea2441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_chain.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2fda1-aed1-4229-9a62-c3a8e00b01ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(question_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66292efb-9aad-4429-986c-ecb10acded17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the chain for serveral times for differnt inputs, and then print the buffer to see how things are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1456f-8b8f-4a1b-b146-0ecf6e6f48b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92f39e-eb3f-4e95-8aa4-f31b70d9eb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now, how can I have define the amount of conversations that are needed to be saved?\n",
    "# By using ConversationBufferWindowMemory(k=<number_of_past_mem_to_save>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430db16-72d5-411a-bd36-123b18d5c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a491a-9fec-4271-b4ca-4b73e4493016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf46f4-5adb-4746-8ec2-7e8586d886ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966625d1-46c5-430c-90c6-be311ea5c83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# when using 1, it means it does not actually use memory\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "question_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"question\", memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ae25c-48a3-40f0-8c99-e825fbe39d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = question_chain.invoke({\"topic\": \"supercomputers\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ac144-2b63-41b3-97c8-09e810799c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_chain.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5fa8f-ba00-4156-b035-b42c82b4c927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(question_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132d771-b2bf-446e-b95c-bc7443c6988e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79ab9e-333c-4b36-9c94-9d688f4ffb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
