{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f833961-7d18-41d1-9c4b-39a71bbbbad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# April 2025\n",
    "# running shell command with agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f27bc-68c8-4c25-9629-9868fd6cb13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078aef9f-48ef-4f74-be3d-77fc146ea7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f2e8d-1d08-494e-bca6-cebd44c873e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.shell.tool import ShellTool\n",
    "\n",
    "# Optional: to capture output instead of printing directly\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# # Initialize LLM (you can use ChatOpenAI or any other)\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Initialize the Shell tool\n",
    "shell_tool = ShellTool()\n",
    "\n",
    "# Create an agent that uses the shell tool\n",
    "agent = initialize_agent(\n",
    "    tools=[shell_tool],\n",
    "    llm=llm,\n",
    "    agent= AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    # verbose=True,\n",
    ")\n",
    "\n",
    "# Example command\n",
    "agent.run(\"List all files in the current directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f26abe-7719-4958-b871-1568b24044fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304e793-39ca-42ef-b66b-18259652af6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc297d7d-a47c-485a-ab47-7cd30c650c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5cc50b-52a0-4bde-9433-90e1820b231b",
   "metadata": {},
   "source": [
    "## output with parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23557b1-7206-4a98-8fcd-77e9f63ed533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e26eb-efd9-4e6d-8fd6-bb6f524a32a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_community.tools.shell.tool import ShellTool\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "\n",
    "# ðŸ”¹ 1. Define a structured response schema\n",
    "class DirectoryListing(BaseModel):\n",
    "    files: list[str] = Field(description=\"List of file and directory names\")\n",
    "\n",
    "# ðŸ”¹ 2. Create a parser for the schema\n",
    "parser = PydanticOutputParser(pydantic_object=DirectoryListing)\n",
    "\n",
    "# ðŸ”¹ 3. Custom shell logic for structured output\n",
    "def list_files(_):\n",
    "    import os\n",
    "    return {\"files\": os.listdir(\".\")}\n",
    "\n",
    "# ðŸ”¹ 4. Wrap the function as a LangChain Tool\n",
    "list_files_tool = Tool(\n",
    "    name=\"ListFilesTool\",\n",
    "    func=lambda _: json.dumps(list_files(None)),  # Convert the output to a JSON string\n",
    "    description=\"Lists files in the current directory and returns them in structured JSON format.\"\n",
    ")\n",
    "\n",
    "# ðŸ”¹ 5. Initialize ShellTool (for general shell access)\n",
    "shell_tool = ShellTool()\n",
    "\n",
    "# # ðŸ”¹ 6. Initialize LLM\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ðŸ”¹ 7. Build the agent with tools\n",
    "agent = initialize_agent(\n",
    "    tools=[list_files_tool, shell_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# ðŸ”¹ 8. Run the agent with a natural prompt\n",
    "response = agent.run(\"List all files in the current directory as JSON\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e17b4-a9db-411c-a3f4-35afa990d44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed6f56-9049-459b-9378-1b5a6548b04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
