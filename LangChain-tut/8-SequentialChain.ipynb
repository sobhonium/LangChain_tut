{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819415eb-b26b-4d9e-9a15-56a9c614e1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# April 2025\n",
    "# SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d751fb-06b0-4676-9845-d1211e674518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7cbe7-15f8-498b-a1b8-f487064fcc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bab65-2f25-4b88-8c05-dca6e0f310ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e798f-3ed7-4380-ba58-9ae2517b4c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f17e3-90d3-467a-bd21-86f461986f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ace7b4-a92d-44fc-b89b-8e9c523ae9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Define prompts\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate a factual question about {topic}.\",\n",
    ")\n",
    "\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the question: {question}\",\n",
    ")\n",
    "\n",
    "# Step 3: Define LLM chains\n",
    "question_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"question\")\n",
    "answer_chain = LLMChain(llm=llm, prompt=answer_prompt, output_key=\"answer\")\n",
    "\n",
    "# Step 4: Create SequentialChain\n",
    "chain = SequentialChain(\n",
    "    chains=[question_chain, answer_chain],\n",
    "    input_variables=[\"topic\"],\n",
    "    output_variables=[\"question\", \"answer\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb134846-659a-4039-97da-2aef7c1672bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24908d34-d575-4539-9c8d-8ff7d477c69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chain.invoke({\"topic\": \"supercomputers\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba015ac1-0cce-42b9-9ec2-c9a5ecaf5ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76ba3f-bc62-49d1-a78d-b4a6f944accd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b599a0-9bf9-4d9c-9e7d-e9a761f8ad27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "tools = load_tools([\"wikipedia\",   \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d1dcb-50ce-4a43-ace3-9b1b8a026b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"As of now, what countries are qualifies so far to be playig in world cup 2026?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10974b6d-c1fe-4db1-9cb4-f58864bb3803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df95a97-5289-4e0b-9ca2-997aeabd5991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
