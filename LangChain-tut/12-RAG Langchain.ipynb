{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16b45da-b741-4129-ba6e-ecd5cf845036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG with Langchain\n",
    "# source: https://python.langchain.com/docs/concepts/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b94b6d-7c1f-461b-94e5-393ca6dfc940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2199d9-32d4-4ed0-b9b8-5c241e4c11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044ade83-a6f6-4de6-b21c-1c2579debdae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3daff7bd-f352-4bbc-a87e-0a7cf06f638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b7070-6f2f-4b9e-9342-ef1b09221f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53788d7-5105-407c-9435-e7d728171d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 176, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain_community.chat_models import ChatGroq\n",
    "import os\n",
    "\n",
    "# # 1. Set your Groq API key\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key\"\n",
    "\n",
    "# 2. Load and split your text\n",
    "text = \"\"\"\n",
    "The company said the Starship \"experienced a major anomaly\" at about 11 p.m. while on the test stand preparing for the tenth flight test at Starbase, SpaceX's launch site at the southern tip of Texas.\n",
    "\n",
    "\"A safety clear area around the site was maintained throughout the operation and all personnel are safe and accounted for,\" SpaceX said in a statement on the social platform X.\n",
    "\n",
    "It marked the latest in a series of incidents involving Starship rockets. On Jan. 16, one of the massive rockets broke apart in what the company called a \"rapid unscheduled disassembly,\" sending trails of flaming debris near the Caribbean. Two months later, Space X lost contact with another Starship during a March 6 test flight as the spacecraft broke apart, with wreckage seen streaming over Florida.\n",
    "\"\"\"\n",
    "splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "docs = splitter.create_documents([text])\n",
    "\n",
    "# 3. Use HuggingFace Embeddings (local + open source)\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Store embeddings in FAISS\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# # 5. Use Groq's LLM (Mixtral here)\n",
    "# llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# 6. Create a RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# 7. Ask a question\n",
    "query = \"What happend to Space X recently?\"\n",
    "answer = qa.run(query)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fa351-4911-4397-9141-e236420c5b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8215b13-4050-4aea-ac52-0ee1efe4f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18490b51-66fe-40be-95df-c515e75aa716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e9882-a456-4901-b3d6-240694cb8b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Define a system prompt that tells the model how to use the retrieved context\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Context: {context}:\"\"\"\n",
    "    \n",
    "# Define a question\n",
    "question = \"\"\"why the spacecraft failed?\"\"\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "# Combine the documents into a single string\n",
    "docs_text = \"\".join(d.page_content for d in docs)\n",
    "\n",
    "# Populate the system prompt with the retrieved context\n",
    "system_prompt_fmt = system_prompt.format(context=docs_text)\n",
    "\n",
    "# # Create a model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# Generate a response\n",
    "questions = llm.invoke([SystemMessage(content=system_prompt_fmt),\n",
    "                          HumanMessage(content=question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b95b36-07cb-4ad4-9d89-4fab52e1d5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3ba6c-1036-4a9d-a641-e39ab189682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfa2dc-9f95-4ddb-ad24-b716824b8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae91da0-3226-482b-a8e8-e621bdc44366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070780c-f313-4e40-9ade-598ad04182ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the transcript of a video (url given)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94581e-8f1d-4939-a1f8-01c4a5a6b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/sJ9kSzMbMRY?si=k4dnmxrt-yMkuSAy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa5722-d829-4c7c-a9c5-1621c316b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def extract_video_id(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
    "        return parse_qs(parsed_url.query).get('v', [None])[0]\n",
    "    elif parsed_url.hostname == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "video_url = \"https://youtu.be/sJ9kSzMbMRY?si=k4dnmxrt-yMkuSAy\"\n",
    "video_id = extract_video_id(video_url)\n",
    "print(\"Video ID:\", video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc723ca2-cea8-4fb7-845f-32d03d6964b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66b635-fb61-47e7-8f17-f777e603a09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f45706-1015-4282-90c0-e10e7e0817cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = extract_video_id(video_url)\n",
    "if video_id:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    full_text = \" \".join([entry['text'] for entry in transcript])\n",
    "    print(full_text)\n",
    "else:\n",
    "    print(\"Could not extract video ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d4ecf-c1f2-4762-b187-8e0849211faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b2792-c135-41b7-9693-1c96f9d4f427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01909c55-b3f5-4b59-9ab1-fbd7c2bb4c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
