{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96310ff-5d8b-44fb-9db6-5477415bc410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3df22e-b6d5-4a6d-8c5d-1bf553d8b526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grammar checker for phd file paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7795e26-e189-43ef-b1b7-025e536d3321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20927a83-ddf5-41c5-b303-6767fecd7afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8705ac4-2535-4428-ad50-8f1bcaf89718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langchain  google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8098f64-b21d-4e83-931d-dbeea4db4f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf4840-c413-4d58-bca5-a0dc1a85721e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807c7e8-397d-4204-8283-81d925e98133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7efb2-d874-41c2-b9db-97fee5db4c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b155d42-93b8-4169-84fd-f0d6df13acc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Recommend me a laptop for moderate gaming activities\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb9e5d-4645-4655-b50c-d2932c17fd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead2bbe-0db9-4917-a0d0-ba243b8fc397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811210c-8a1d-4cc9-ae10-8bcab4e01cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c40e43-e6eb-4bdc-b804-bd04458d2d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7041f-a986-4ca4-9965-0d7f0e096aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612c858-3630-44f1-a7ab-560fcc2460c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1545e93-c7aa-4d92-ab6b-dad1a149c78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the prompt using PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Hi how are you? Tell me something about {topic}.\"\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain with an input for 'topic'\n",
    "response = chain.run(\"AI and Machine Learning\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e4636-9071-4554-8749-d92841a006a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe5663-418e-45b6-9ffb-daa97d426882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d84d066-b477-475b-b0ce-71df52b68c89",
   "metadata": {},
   "source": [
    "# grammar checker for phd file paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7886f-caf6-4aad-87a4-7425a0e77cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set up your model (this can be replaced with another chat model)\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Create system and human message templates\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a grammar chekcing assistant that checks the transparency of a text that is supposed to be part of a phd research.\"\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"Can you correct {phd_paragraph} and rewrite it?\"\n",
    ")\n",
    "\n",
    "# Combine into a chat prompt\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "# Build the chain\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "# Run the chain with input\n",
    "response = chain.run({\"phd_paragraph\": \"After years of research, scientists have realized that using sugar in human diet is not as lethal as sedantry lifestyle. You can have a considerable amount of sugar and have a perfect life as longs as you remain active on a day-to-day bases. However, if you are not active, even careful selection of food ingriendents and cutting off sugar can not gaurantee your wellbeings.\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be90313-1e79-40d3-a0d8-7fa987b15a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
