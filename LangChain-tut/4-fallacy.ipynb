{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48afcf-f929-4db8-be9d-fdf935978f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# April 2025\n",
    "# Fallacy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80237a36-48b2-4541-8dfa-70879bb9a834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c71ed6f6-4536-412e-a358-9c8c0245853a",
   "metadata": {},
   "source": [
    "despite ChatPromptTemplate being use as explicity like bellow:\n",
    "\n",
    "ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a critical reasoning assistant.\"),\n",
    "    (\"user\", \"Given the following argument... Argument: {argument}\")\n",
    "])\n",
    "\n",
    "you can implicity put roles in tamples:\n",
    "    \n",
    "    \n",
    "fallacy_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a critical reasoning assistant.\n",
    "\n",
    "Given the following argument, do the following:\n",
    "- Detect if there is a logical fallacy.\n",
    "- Identify the fallacy type (if any).\n",
    "- Rewrite the argument to eliminate the fallacy but keep the main point.\n",
    "\n",
    "Respond in JSON format with keys: fallacy_detected (true/false), fallacy_type, revised_text.\n",
    "\n",
    "Argument: \"{argument}\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d96ce-06b8-4c28-94f9-0db06c709b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b27bf6-138f-42ce-aa0f-2170fdb0fb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2c2ba-3840-47c8-9101-5febd712c41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c21937-7b6b-42dc-b6ff-6fd6e5dd2bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb646a5-4b8c-469a-a04f-4495fa9ce662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# # 1. Set up the LLM\n",
    "# llm = ChatOpenAI(temperature=0.2)\n",
    "\n",
    "# 2. Define the prompt\n",
    "fallacy_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a critical reasoning assistant.\n",
    "\n",
    "Given the following argument, do the following:\n",
    "- Detect if there is a logical fallacy.\n",
    "- Identify the fallacy type (if any).\n",
    "- Rewrite the argument to eliminate the fallacy but keep the main point.\n",
    "\n",
    "Respond in JSON format with keys: fallacy_detected (true/false), fallacy_type, revised_text.\n",
    "\n",
    "Argument: \"{argument}\"\n",
    "\"\"\")\n",
    "\n",
    "# fallacy_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"\"\"\n",
    "#                 You are a critical reasoning assistant.\n",
    "#                 \"\"\"),\n",
    "\n",
    "#     # MessagesPlaceholder(variable_name=\"history\"),\n",
    "#     (\"user\", \"\"\"\n",
    "\n",
    "#                 Given the following argument, do the following:\n",
    "#                 - Detect if there is a logical fallacy.\n",
    "#                 - Identify the fallacy type (if any).\n",
    "#                 - Rewrite the argument to eliminate the fallacy but keep the main point.\n",
    "\n",
    "#                 Respond in JSON format with keys: fallacy_detected (true/false), fallacy_type, revised_text.\n",
    "\n",
    "#                 Argument: \"{argument}\"\n",
    "#                 \"\"\")\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824d92f-09d2-48a3-8eee-e94a4161e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacy_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46839cf-2be1-411f-847d-21b5219d9ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb29d0e-840f-4f08-a7d0-7626c656ea3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Create the Chain\n",
    "fallacy_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=fallacy_prompt,\n",
    "    output_key=\"fallacy_result\"\n",
    ")\n",
    "\n",
    "# 4. Create a simple runner function\n",
    "def detect_and_fix_fallacy(argument: str):\n",
    "    result = fallacy_chain.run(argument=argument)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "user_argument = \"You can't trust anything John says about politics because he's an idiot.\"\n",
    "\n",
    "user_argument = \"\"\"I've gathered my principles over the years and each and every time I'm updating\n",
    "them. Many of people's attitudes don't make sense. Since, I cannot change people around me, I can at least do something to \n",
    "decrese the effect of their wrong attitudes by knowing how to behave when I meet them again.\n",
    "I can take notes about them and define pricinples for each person for myself of how I should deal\n",
    "with them based on our past communications. \n",
    "\n",
    "The purpose of\n",
    "such attempt is to know how to deal with situations in\n",
    "future under the same cricumstances to avoid failures and act wisely.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_argument = \"\"\"LangChain is an advanced NLP framework designed to improve the way language models handle tasks by incorporating logical reasoning.\n",
    "It enables models to generate more coherent, contextually accurate responses by simulating a chain of thought process.\"\"\"\n",
    "\n",
    "user_argument = \"I need a break to get back to work fresh to be able to work perfectly.\"\n",
    "output = detect_and_fix_fallacy(user_argument)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272887f5-54be-4e2d-a276-920accecd80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff9d73-37fb-4724-8506-f6ebc960fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba878f05-ca4b-4015-8cb3-cd8363a70499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab36297e-5bd5-43dd-bcf0-5c8e92770ee5",
   "metadata": {},
   "source": [
    "| Fallacy Name         | What It Means                                             | Example                                                                 |\n",
    "|:---------------------|:----------------------------------------------------------|:-----------------------------------------------------------------------|\n",
    "| **Ad Hominem**        | Attacking the person instead of the argument.             | \"You're wrong because you're ugly.\"                                    |\n",
    "| **Strawman**          | Misrepresenting someone's argument to make it easier to attack. | \"He wants better school lunches, so he must hate teachers.\"        |\n",
    "| **Appeal to Authority** | Claiming something is true because an authority says so. | \"It's true because a scientist said it.\"                               |\n",
    "| **Slippery Slope**    | Saying one step will inevitably lead to an extreme outcome. | \"If we allow masks, next we'll be forced to wear hazmat suits forever!\" |\n",
    "| **False Dilemma**     | Presenting only two options when more exist.              | \"You're either with us or against us.\"                                 |\n",
    "| **Post Hoc** (False Cause) | Assuming that because B follows A, A caused B.        | \"I wore my lucky socks and we won. It must be the socks!\"               |\n",
    "| **Bandwagon**         | Arguing something must be true because many people believe it. | \"Everyone's doing it, so it must be right.\"                         |\n",
    "| **Circular Reasoning** | When the conclusion is just a restatement of the premise. | \"I'm right because I say so.\"                                          |\n",
    "| **Appeal to Emotion** | Using emotion instead of valid logic to persuade.         | \"Think of the children!\"                                                |\n",
    "| **Red Herring**       | Distracting from the real argument with irrelevant info.  | \"Why worry about the environment when there are so many unemployed people?\" |\n",
    "| **Hasty Generalization** | Making a broad statement based on too little evidence. | \"I met two rude New Yorkers. All New Yorkers must be rude.\"             |\n",
    "| **Burden of Proof**   | Shifting the obligation to disprove your claim onto others. | \"Prove that aliens *don't* exist!\"                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf2bdb-2800-4619-abe9-c65b9aeddab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5de252-fdfe-4f33-b72b-181037a95a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717cae44-29fd-4065-9f66-fa604e0af21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "user_argument = \"If we allow masks, next we'll be forced to wear hazmat suits forever!\"\n",
    "output = detect_and_fix_fallacy(user_argument)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cc05b-f881-4854-9fb1-dc58c6b756b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6c2de-33cb-4cf0-ba7f-3081242bd6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351f75d-36ef-4c23-a902-02e202dceb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "user_argument = \"It's true because a scientist said it.\"\n",
    "output = detect_and_fix_fallacy(user_argument)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e0ac3-8b9f-460d-81fb-63525c3390df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e76ce4-cafb-487b-a86b-047f4d5c4251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549d7a2-b71d-43fc-a3ba-83e562d0be13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_argument = \"\"\"The people from Xnoro Island have deficiency in their skin cells and it makes them look\n",
    "older than their peers from the rest of the world. This is rooted to the reduced age of intercourse\n",
    "in this country.\n",
    "\"\"\"\n",
    "output = detect_and_fix_fallacy(user_argument)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c448b0a0-7305-4d7f-9f8d-646bf607b9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f566f3a-e935-4e4e-9e5a-fb5aa3e15af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea0242-17bf-41dc-9b02-6066564d4af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_argument = \"\"\"He wants better school lunches, so he must hate teachers.\n",
    "\"\"\"\n",
    "output = detect_and_fix_fallacy(user_argument)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c334be-518f-40c5-a79a-07897e89e0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
