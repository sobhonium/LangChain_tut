{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929285ee-3f8c-41f1-a8d8-7f1833794996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# June 2025\n",
    "# The attempt is to generate graph knowledge using llms on neo4j database\n",
    "# Don't fret things might not look perfect on graphs, as here Groq is used.\n",
    "# Surely, openai can lead to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd4c367-4b49-426e-ae72-ff3bc97858ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's best if you learn abit about how cypher scripts are written and run\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aeaa1f-39c6-457e-9ffd-f3fe54aaf54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694307be-b9bf-4e74-977d-a091c1dee182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1st method: using .env file.\n",
    "load_dotenv()\n",
    "# Access them using os.getenv or os.environ\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# 2nd method: using hard code\n",
    "# api_key = \"<put the api key here>\"\n",
    "# if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "#     os.environ[\"GROQ_API_KEY\"] = api_key #getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a95e3-3b6e-44ae-966d-df019d314e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ede57-eb25-4980-84fd-75756ada9b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8942e69b-75d7-4d0f-a8c3-a6795f601ae4",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "- Download Neo4j Desktop\n",
    "https://neo4j.com/download/\n",
    "- Install and launch it\n",
    "- Create a new project and new database\n",
    "  Click \"New Project\" → \"Add\" → \"Local DB\"\n",
    "  Set a password (remember this for your Python code!)\n",
    "  Start the database\n",
    "- Find Bolt URL and Credentials\n",
    "  The Bolt URL will look like bolt://localhost:7687\n",
    "  Username is usually neo4j\n",
    "  Password is what you set during creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0abea-36fd-414b-9451-0b311484182e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dec630-87f6-45ad-bb70-673a18cfd1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"12345678\",  # Use the password you set\n",
    "    refresh_schema=False  # 👈 SKIP the APOC call\n",
    ")\n",
    "print(graph.query(\"RETURN 'Connected to Neo4j' AS message\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e852f-e800-41a9-b01c-a6b979af177c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b885decd-8320-4900-bc3f-2168a3f429c4",
   "metadata": {},
   "source": [
    "## LLM Graph Transformer\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "539e1197-6f1e-40a5-af9a-d47c5394c430",
   "metadata": {},
   "source": [
    "Extracting graph data from text enables the transformation of unstructured information into structured formats, facilitating deeper insights and more efficient navigation through complex relationships and patterns. The LLMGraphTransformer converts text documents into structured graph documents by leveraging a LLM to parse and categorize entities and their relationships. The selection of the LLM model significantly influences the output by determining the accuracy and nuance of the extracted graph data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979bcf4-5f6a-45e6-b622-8138c104aee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8500d04-95e7-486d-b314-8e05123b0307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1da43-f07c-4e57-b394-61db02fd081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e3b58-dc99-4d68-93d9-c0af77756ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe5231-a0e9-4c36-9a0d-4008f09c67ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we can pass in example text and examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7457eb3-3ba8-45a5-92b7-f12866924997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Born in Rosario, Argentina, in 1987, Lionel Messi is widely regarded as one of the greatest \n",
    "football players of all time, and his illustrious career proves why. The Argentinean \n",
    "footballer, who holds a record eight Ballon d'Or awards, has displayed his talent \n",
    "early on and has always been destined for greatness.\n",
    "\n",
    "When Messi was 13 years old, he and his family moved to Barcelona, \n",
    "where the club assisted him in treating his growth hormone deficiency. \n",
    "He started playing for FC Barcelona's U14 team. The Argentinean quickly \n",
    "rose through the ranks, impressing everyone with exceptional skills and \n",
    "talent. At 17, he made his first senior appearance for the club and \n",
    "became a vital player for the Blaugranas.\n",
    "\n",
    "The Rosario's native relationship with Barcelona was very successful. \n",
    "During his 17-year career with the team, he  won numerous \n",
    "titles, including 10 La Liga titles, four Champions League crowns, \n",
    "and seven Copa del Rey trophies. He is also the all-time leading scorer \n",
    "in La Liga, with an incredible 474 goals to his name. He left the Spanish \n",
    "club in 2021 to join French powerhouse Paris Saint Germain, where he played \n",
    "two years before joining Inter Miami in the MLS.\n",
    "\n",
    "Lionel Messi has always been playing against Christiano Ronaldo who is also a \n",
    "top football player. Christiano Ronaldo is from Iran, played in Real Madrid and Manchester for ages.\n",
    "They face each other several times in this decade and\n",
    "each scored several goals for their teams. Christiano won the title of being the best\n",
    "player in 10 seasons in la legua.\n",
    "\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9d2df-3362-4933-a518-b79b3fc6d907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b839fd-44b5-4b87-ab9f-808c12240132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6f4f5-30f8-4597-9f1d-c443c49c82ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3f8ba121-a8f2-49b6-ad19-97d5e2596ec6",
   "metadata": {},
   "source": [
    "Note that the graph construction process is non-deterministic since we are using LLM. Therefore, you might get slightly different results on each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f289e14-783c-4b46-933a-95eea280f064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additionally, you have the flexibility to define specific types of nodes and \n",
    "# relationships for extraction according to your requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9af52d-1427-4fac-b2b5-31de2fff6cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Try one of these or anything similar as they give you graph structures\n",
    "\n",
    "## 1)\n",
    "# llm_transformer_filtered = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[\"Person\", \"Country\", \"Team\", \"Prize\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\",  \"PLAYED_FOR\", \"WON\", \"PLAYED_AGAINST\"],\n",
    "# )\n",
    "# graph_documents_filtered = await llm_transformer_filtered.aconvert_to_graph_documents(\n",
    "#     documents\n",
    "# )\n",
    "# print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "# print(f\"Relationships:{graph_documents_filtered[0].relationships}\")\n",
    "\n",
    "\n",
    "\n",
    "## 2)\n",
    "\n",
    "allowed_relationships = [\n",
    "    (\"Person\", \"PLAYED_FOR\", \"Team\"),\n",
    "    (\"Person\", \"NATIONALITY\", \"Country\"),\n",
    "    (\"Person\", \"PLAYED_AGAINST\", \"Person\"),\n",
    "    (\"Person\", \"WON\", \"Title\"),\n",
    "]\n",
    "\n",
    "llm_transformer_tuple = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Team\", \"Title\"],\n",
    "    allowed_relationships=allowed_relationships,\n",
    ")\n",
    "graph_documents_filtered = await llm_transformer_tuple.aconvert_to_graph_documents(\n",
    "    documents\n",
    ")\n",
    "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93408be9-c5cc-4710-884d-39f448411703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graph_documents_filtered[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea40191-6e5f-4f84-9bcb-0d5d68b36b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_documents = graph_documents_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f0d09-a463-4f3a-985a-82e89e209ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for node in graph_documents[0].nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b804c-8ba6-44e8-af9b-cbab9e30d54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ae5f4-b07b-40f9-a713-4361c193f53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(rel.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faaf729-e19e-4ee6-adcd-70c1a7061726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f8402-6108-4948-8a9d-9a2a7abf9041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(rel.source.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22053b2e-861c-4dbc-abee-4efd08ed5d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd63cc-d84c-4cf8-ab8d-56c6e35340df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(rel.target.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa956bf3-b28b-4c1f-acf3-8eeebf5a846f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00992f5-a868-4263-98a8-9cd50cf776f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(rel.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31735c55-dacd-4786-a050-3f6800dd5a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(rel.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14422a18-baae-4c30-a9c4-2d7efcd95865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d123c46-9f1c-4ee7-890d-43a670678894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rel in graph_documents[0].relationships:\n",
    "    print(f\"\"\"\n",
    "              merge (p1:{rel.source.type}{{ name:\"{rel.source.id}\"}})\n",
    "              merge (p2:{rel.target.type}{{ name:\"{rel.target.id}\"}})\n",
    "              merge (p1)-[:{rel.type}]->(p2)\n",
    "          \"\"\")\n",
    "    # print(rel.source.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a534b0b-3a9b-4a02-8414-4c527e57b234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge vs create:\n",
    "# create creates a node and relationsihp and it might be redundant.\n",
    "# merge, however, can look at the existing nodes and if they are existed \n",
    "# does not add new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed75b5-032d-4d44-b199-414927a41bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f748bf-fa3f-4aab-b611-9b2361e1f7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "nodes = graph_documents_filtered[0].nodes\n",
    "relationships = graph_documents_filtered[0].relationships\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "\n",
    "with driver.session() as session:\n",
    "    for rel in graph_documents[0].relationships:\n",
    "        cypher = f\"\"\"\n",
    "              merge (p1:{rel.source.type}{{ name:\"{rel.source.id}\"}})\n",
    "              merge (p2:{rel.target.type}{{ name:\"{rel.target.id}\"}})\n",
    "              MERGE (p1)-[:{rel.type}]->(p2)\n",
    "          \"\"\"\n",
    "        session.run(cypher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed72d1-bdbd-4fef-b791-1f1f765aa5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now you can go to neo4j browser and run \n",
    "# match (n) return n\n",
    "# to see the graph structures you just gerenrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b9b36-6897-4196-8ff3-dc04b00f2dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading from neo4j:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729499f-b55b-48ca-be94-c3cc43a75a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26e549-d8d4-49ed-8c9a-c89322e7aa1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51e975-3029-4140-9430-133c543a023a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def get_all_nodes(tx):\n",
    "    result = tx.run(\"MATCH (n) RETURN n\")\n",
    "    nodes = []\n",
    "    for record in result:\n",
    "        node = record[\"n\"]\n",
    "        nodes.append({\n",
    "            \"id\": node.id,\n",
    "            \"labels\": list(node.labels),\n",
    "            \"properties\": dict(node.items())\n",
    "        })\n",
    "    return nodes\n",
    "\n",
    "def get_all_relationships(tx):\n",
    "    result = tx.run(\"MATCH (a)-[r]->(b) RETURN a, r, b\")\n",
    "    relationships = []\n",
    "    for record in result:\n",
    "        a = record[\"a\"]\n",
    "        b = record[\"b\"]\n",
    "        r = record[\"r\"]\n",
    "        relationships.append({\n",
    "            \"start_id\": a.id,\n",
    "            \"start_name\": a.get(\"name\", \"\"),\n",
    "            \"type\": r.type,\n",
    "            \"end_id\": b.id,\n",
    "            \"end_name\": b.get(\"name\", \"\"),\n",
    "            \"properties\": dict(r.items())\n",
    "        })\n",
    "    return relationships\n",
    "\n",
    "with driver.session() as session:\n",
    "    nodes = session.read_transaction(get_all_nodes)\n",
    "    relationships = session.read_transaction(get_all_relationships)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Print nodes\n",
    "print(\"=== NODES ===\")\n",
    "for node in nodes:\n",
    "    print(f\"ID: {node['id']}, Labels: {node['labels']}, Properties: {node['properties']}\")\n",
    "\n",
    "# Print relationships\n",
    "print(\"\\n=== RELATIONSHIPS ===\")\n",
    "for rel in relationships:\n",
    "    print(f\"({rel['start_name']} [{rel['start_id']}]) -[:{rel['type']}]-> ({rel['end_name']} [{rel['end_id']}]) Properties: {rel['properties']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61967c3a-feac-4e44-8cb6-c94e511cd8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b864163-fde8-42d9-824c-78e08253b426",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ccbb8-4d1a-4157-a2a7-e8f9fb51d445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ec5da770-ab7f-4e0b-8c72-5259d18f4001",
   "metadata": {},
   "source": [
    "now, since you already have a knowledge graph in Neo4j (with nodes and relationships extracted from text), you can now use it for RAG (Retrieval-Augmented Generation) by combining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1c4f0-640e-4c74-b5b0-da4815c3fd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a69e4b96-b8d9-4000-9ba7-8908bd53ae23",
   "metadata": {},
   "source": [
    "LangChain supports a built-in graph QA chain that will:\n",
    "\n",
    "Accept a natural language question\n",
    "Translate it to Cypher\n",
    "Query the KG\n",
    "Feed results to the LLM for final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb6d8e-3500-4b24-8156-2bf8ae429c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685a237-21b2-4350-81e0-8c02992ae8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_text = \"\"\"=== NODES ===\n",
    "=== NODES ===\n",
    "ID: 1, Labels: ['Team'], Properties: {'name': 'Inter Miami'}\n",
    "ID: 2, Labels: ['Person'], Properties: {'name': 'Christiano Ronaldo'}\n",
    "ID: 3, Labels: ['Team'], Properties: {'name': 'Real Madrid'}\n",
    "ID: 4, Labels: ['Team'], Properties: {'name': 'Manchester'}\n",
    "ID: 5, Labels: ['Country'], Properties: {'name': 'Iran'}\n",
    "ID: 6, Labels: ['Country'], Properties: {'name': 'Argentina'}\n",
    "ID: 13, Labels: ['Person'], Properties: {'name': 'Lionel Messi'}\n",
    "ID: 14, Labels: ['Team'], Properties: {'name': 'Barcelona'}\n",
    "ID: 15, Labels: ['Team'], Properties: {'name': 'Paris Saint Germain'}\n",
    "\n",
    "=== RELATIONSHIPS ===\n",
    "(Christiano Ronaldo [2]) -[:PLAYED_FOR]-> (Real Madrid [3]) Properties: {}\n",
    "(Christiano Ronaldo [2]) -[:PLAYED_FOR]-> (Manchester [4]) Properties: {}\n",
    "(Christiano Ronaldo [2]) -[:NATIONALITY]-> (Iran [5]) Properties: {}\n",
    "(Lionel Messi [13]) -[:PLAYED_FOR]-> (Inter Miami [1]) Properties: {}\n",
    "(Lionel Messi [13]) -[:PLAYED_FOR]-> (Barcelona [14]) Properties: {}\n",
    "(Lionel Messi [13]) -[:PLAYED_FOR]-> (Paris Saint Germain [15]) Properties: {}\n",
    "(Lionel Messi [13]) -[:NATIONALITY]-> (Iran [5]) Properties: {}\n",
    "(Lionel Messi [13]) -[:NATIONALITY]-> (Argentina [6]) Properties: {}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd8e4d-cb19-4e4b-a27c-f4cdbc9fef67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant with access to a knowledge graph.\n",
    "\n",
    "Given the following graph data:\n",
    "\n",
    "{graph_context}\n",
    "\n",
    "Answer this question: {question}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "question = \"Where is Ronaldo from?\"\n",
    "response = rag_chain.run(graph_context=graph_text, question=question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0717144-8c7b-4909-8751-c783b7794555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e1303-c087-4c50-b327-e81b6d24b14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a0d56698-f6ac-4c22-99ee-7b7234326588",
   "metadata": {},
   "source": [
    "If graph_context is large (e.g., tens of thousands of tokens), it will exceed the LLM’s input limit, making direct injection into the prompt infeasible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18df919-47d2-4578-9942-5856bebf073a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one idea is this (use retrivers and embeddings). This is just the\n",
    "# same as before for RAGing every text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5facef3-2872-4e91-80b3-a4fe42bd81d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def extract_triples():\n",
    "    triples = []\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (s)-[r]->(o) RETURN s.name AS subject, type(r) AS predicate, o.name AS object\")\n",
    "        for record in result:\n",
    "            subj = record[\"subject\"]\n",
    "            pred = record[\"predicate\"].replace(\"_\", \" \").lower()\n",
    "            obj = record[\"object\"]\n",
    "            triple_text = f\"{subj}  {pred} {obj}\"\n",
    "            triples.append(triple_text)\n",
    "    return triples\n",
    "\n",
    "triple_strings = extract_triples()\n",
    "\n",
    "# 2. Wrap each triple as its own Document\n",
    "docs = [Document(page_content=triple) for triple in triple_strings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ba453-e64a-4b36-8e1a-007d18722049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "triple_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a8103-4bba-438b-b50b-6d5fe360d0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fdae9-e6b0-4c95-95bd-68a14d29019f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain_community.chat_models import ChatGroq\n",
    "import os\n",
    "\n",
    "# Step 2: Embed and store in FAISS\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 3: LLM for answering\n",
    "# llm = ChatOpenAI()  # Or ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Step 4: QA Chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Step 5: Ask a question\n",
    "query = \"Where is Ronaldo from?\"\n",
    "answer = qa.run(query)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2dea44-172c-489a-a4a4-0bddfa5f60c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "17cfd594-f868-4431-98ef-4404fd78b7e0",
   "metadata": {},
   "source": [
    "What you’re experiencing is LLM override of the RAG context — a common issue when using retrieval-augmented generation (RAG). Here's why it's happening and how to fix it.\n",
    "\n",
    "❓ Why is it happening?\n",
    "Even though your graph says “Ronaldo is from Iran”, the LLM (like OpenAI or HuggingFace models) still has strong prior knowledge that:\n",
    "\n",
    "“Ronaldo is from Portugal.”\n",
    "Unless your retrieved context is very clearly worded and dominant, the LLM will default to what it already “knows.”\n",
    "\n",
    "✅ Solution: Make Retrieved Context More Explicit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb5a6a-d3db-4777-9ac5-59493367a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b53be-0738-4731-af29-d3c88a860f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f2f07-b7d3-46d5-bfa2-1b1f384233ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b1757-1f19-4207-8ee3-68d58ae4718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources:\n",
    "# https://python.langchain.com/docs/how_to/graph_constructing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
